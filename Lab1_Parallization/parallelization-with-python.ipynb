{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Parallel Processing in Python\n",
    "\n",
    "Parallel processing is a mode of operation where the task is executed simultaneously in multiple processors in the same computer. It is meant to reduce the overall processing time.\n",
    "\n",
    "However, there is usually a bit of overhead when communicating between processes which can actually increase the overall time taken for small tasks instead of decreasing it.\n",
    "\n",
    "In python, the `multiprocessing` module is used to run independent parallel processes by using subprocesses (instead of threads). It allows you to leverage multiple processors on a machine (both Windows and Unix), which means, the processes can be run in completely separate memory locations.\n",
    "\n",
    "By the end of this lab you will know:\n",
    "\n",
    "* How to structure the code and understand the syntax to enable parallel processing using `multiprocessing`?\n",
    "* How to implement synchronous and asynchronous parallel processing?\n",
    "* How to parallelize a `Pandas` DataFrame?\n",
    "* Solve 3 different use cases with the `multiprocessing.Pool()` interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `multiprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the maximum number of parallel processes can you run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Synchronous and Asynchronous execution?\n",
    "\n",
    "In parallel processing, there are two types of execution: Synchronous and Asynchronous.\n",
    "\n",
    "A _synchronous_ execution is one the processes are completed in the same order in which it was started. This is achieved by locking the main program until the respective processes are finished.\n",
    "\n",
    "Asynchronous, on the other hand, doesn’t involve locking. As a result, the order of results can get mixed up but usually gets done quicker.\n",
    "\n",
    "There are 2 main objects in multiprocessing to implement parallel execution of a function: The `Pool` Class and the `Process` Class.\n",
    "\n",
    "### `Pool` Class\n",
    "\n",
    "* Synchronous execution\n",
    "    * `Pool.map()` and `Pool.starmap()`\n",
    "    * `Pool.apply()`\n",
    "    \n",
    "* Asynchronous execution\n",
    "    * `Pool.map_async()` and `Pool.starmap_async()`\n",
    "    * `Pool.apply_async())`\n",
    "\n",
    "### `Process` Class\n",
    "\n",
    "Let’s take up a typical problem and implement parallelization using the above techniques. In this lab, we stick to the `Pool` class, because it is most convenient to use and serves most common practical applications.\n",
    "\n",
    "More info on these classes [here]((https://docs.python.org/3/library/multiprocessing.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Given a 2D matrix (or list of lists), count how many numbers are present between a given range in each row. We will work on the list prepared below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data. Create a matrix of 1 million rows and 5 columns filled with random integers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(100)\n",
    "arr = np.random.randint(0, 10, size=[500000, 5])\n",
    "data = arr.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 6, 3, 7, 6],\n",
       " [4, 5, 5, 5, 4],\n",
       " [4, 2, 5, 3, 9],\n",
       " [8, 6, 3, 0, 1],\n",
       " [6, 7, 7, 7, 1],\n",
       " [3, 2, 9, 3, 6],\n",
       " [9, 3, 5, 1, 3],\n",
       " [4, 9, 3, 0, 6],\n",
       " [5, 2, 4, 7, 4],\n",
       " [8, 7, 6, 1, 9]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement solution without parallelization\n",
    "\n",
    "Let’s see how long it takes to compute it without parallelization. For this, we iterate the function `howmany_within_range()` to check how many numbers lie within range and returns the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def howmany_within_range(row, minimum, maximum):\n",
    "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if minimum <= n <= maximum:\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.150521278381348\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "results = []\n",
    "for row in data:\n",
    "    results.append(howmany_within_range(row, minimum=4, maximum=8))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 2, 2, 4, 1, 1, 2, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to parallelize any function?\n",
    "\n",
    "The general way to parallelize any operation is to take a particular function that should be run multiple times and make it run in parallel using different processors.\n",
    "\n",
    "To do this, you initialize a _Pool_ with n number of processors (or cores) and pass the function you want to parallelize to one of _Pools_ parallization methods.\n",
    "\n",
    "`multiprocessing.Pool()` provides the `apply()`, `map()` and `starmap()` methods to make any function run in parallel.\n",
    "\n",
    "Nice! So what’s the difference between `apply()` and `map()`?\n",
    "\n",
    "Both `apply` and `map` take the function to be parallelized as the main argument. But the difference is that `apply()` takes an _args_ argument that accepts the parameters passed to the _function-to-be-parallelized_ as an argument, whereas `map` can take only one _iterable_ as an argument.\n",
    "\n",
    "So `map()` is really more suitable for simpler iterable operations but does the job faster.\n",
    "\n",
    "We will get to `starmap()` once we see how to parallelize `howmany_within_range()` function with `apply()` and `map()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing using `Pool.apply()`\n",
    "\n",
    "Let’s parallelize the `howmany_within_range()` function using `multiprocessing.Pool()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.67092084884644\n",
      "0.05547595024108887\n",
      "135.61527705192566\n",
      "[4, 5, 2, 2, 4, 1, 1, 2, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "# Parallelizing using Pool.apply()\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "t1 = time.time()\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "results = [pool.apply(howmany_within_range, args=(row, 4, 8)) for row in data]\n",
    "t2 = time.time()\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()    \n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "print(t1 - start)\n",
    "print(t2 - t1)\n",
    "\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing using `Pool.map()`\n",
    "\n",
    "`Pool.map()` accepts only one iterable as argument. So as a workaround, I modify the howmany_within_range function by setting a default to the minimum and maximum parameters to create a new `howmany_within_range_rowonly()` function so it accetps only an _iterable list_ of rows as input. This is not a nice usecase of map(), but it clearly shows how it differs from apply()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.380372047424316\n",
      "0.1287531852722168\n",
      "6.251415967941284\n",
      "[3, 3, 1, 1, 2, 5, 4, 3, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# Parallelizing using Pool.map()\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Redefine, with only 1 mandatory argument.\n",
    "def howmany_within_range_rowonly(row, minimum=4, maximum=8):\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if minimum <= n <= maximum:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "start = time.time()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "t1 = time.time()\n",
    "results = pool.map(howmany_within_range_rowonly, [row for row in data])\n",
    "\n",
    "t2 = time.time()\n",
    "pool.close()\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "print(t1 - start)\n",
    "print(t2 - t1)\n",
    "\n",
    "\n",
    "print(results[:10])\n",
    "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing using `Pool.starmap()`\n",
    "\n",
    "In previous example, we have to redefine `howmany_within_range` function to make couple of parameters to take default values. Using `starmap()`, you can avoid doing this. How you ask?\n",
    "\n",
    "Like `Pool.map()`, `Pool.starmap()` also accepts only one iterable as argument, but in `starmap()`, each element in that iterable is also a iterable. You can to provide the arguments to the _function-to-be-parallelized_ in the same order in this inner iterable element, will in turn be unpacked during execution.\n",
    "\n",
    "So effectively, `Pool.starmap()` is like a version of Pool.map() that accepts arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.380495071411133\n",
      "0.04459524154663086\n",
      "17.335542678833008\n",
      "[3, 3, 1, 1, 2, 5, 4, 3, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# Parallelizing with Pool.starmap()\n",
    "import multiprocessing as mp\n",
    "\n",
    "start = time.time()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "t1 = time.time()\n",
    "results = pool.starmap(howmany_within_range, [(row, 4, 8) for row in data])\n",
    "\n",
    "t2 = time.time()\n",
    "pool.close()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "print(t1 - start)\n",
    "print(t2 - t1)\n",
    "\n",
    "print(results[:10])\n",
    "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Parallel Processing\n",
    "\n",
    "The asynchronous equivalents `apply_async()`, `map_async()` and `starmap_async()` lets you do execute the processes in parallel asynchronously, that is the next process can start as soon as previous one gets over without regard for the starting order. As a result, there is no guarantee that the result will be in the same order as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing with Pool.apply_async()\n",
    "\n",
    "`apply_async()` is very similar to apply() except that you need to provide a callback function that tells how the computed results should be stored.\n",
    "\n",
    "However, a caveat with `apply_async()` is, the order of numbers in the result gets jumbled up indicating the processes did not complete in the order it was started.\n",
    "\n",
    "A workaround for this is, we redefine a new `howmany_within_range2()` to accept and return the iteration number (i) as well and then sort the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.20174217224121\n",
      "1.463257074356079\n",
      "0.0007958412170410156\n",
      "30.491361141204834\n",
      "21.98329496383667\n",
      "[1, 1, 2, 5, 2, 3, 4, 4, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing with Pool.apply_async()\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "start = time.time()\n",
    "pool = mp.Pool(4)\n",
    "\n",
    "results = []\n",
    "t1 = time.time()\n",
    "\n",
    "# Step 1: Redefine, to accept `i`, the iteration number\n",
    "def howmany_within_range2(i, row, minimum, maximum):\n",
    "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if minimum <= n <= maximum:\n",
    "            count = count + 1\n",
    "    return (i, count)\n",
    "\n",
    "\n",
    "# Step 2: Define callback function to collect the output in `results`\n",
    "def collect_result(result):\n",
    "    global results\n",
    "    results.append(result)\n",
    "t2 = time.time()\n",
    "\n",
    "# Step 3: Use loop to parallelize\n",
    "for i, row in enumerate(data):\n",
    "    pool.apply_async(howmany_within_range2, args=(i, row, 4, 8), callback=collect_result)\n",
    "t3 = time.time()\n",
    "# Step 4: Close Pool and let all the processes complete    \n",
    "pool.close()\n",
    "pool.join()  # postpones the execution of next line of code until all processes in the queue are done.\n",
    "t4 = time.time()\n",
    "\n",
    "# Step 5: Sort results [OPTIONAL]\n",
    "results.sort(key=lambda x: x[0])\n",
    "results_final = [r for i, r in results]\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "print(t1 - start)\n",
    "print(t2 - t1)\n",
    "print(t3 - t2)\n",
    "print(t4 - t3)\n",
    "\n",
    "print(results_final[:10])\n",
    "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to use `apply_async()` without providing a `callback` function. Only that, if you don’t provide a callback, then you get a list of `pool.ApplyResult` objects which contains the computed output values from each process. From this, you need to use the `pool.ApplyResult.get()` method to retrieve the desired final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing with Pool.apply_async() without callback function\n",
    "\n",
    "import multiprocessing as mp\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "results = []\n",
    "\n",
    "# call apply_async() without callback\n",
    "result_objects = [pool.apply_async(howmany_within_range2, args=(i, row, 4, 8)) for i, row in enumerate(data)]\n",
    "\n",
    "# result_objects is a list of pool.ApplyResult objects\n",
    "results = [r.get()[1] for r in result_objects]\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "print(results[:10])\n",
    "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing with `Pool.starmap_async()`\n",
    "\n",
    "You saw how `apply_async()` works. Can you imagine and write up an equivalent version for starmap_async and map_async? The implementation is below anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelizing with Pool.starmap_async()\n",
    "\n",
    "import multiprocessing as mp\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "results = []\n",
    "\n",
    "results = pool.starmap_async(howmany_within_range2, [(i, row, 4, 8) for i, row in enumerate(data)]).get()\n",
    "\n",
    "# With map, use `howmany_within_range_rowonly` instead\n",
    "# results = pool.map_async(howmany_within_range_rowonly, [row for row in data]).get()\n",
    "\n",
    "pool.close()\n",
    "print(results[:10])\n",
    "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Use `Pool.apply()` to get the row wise common items in list_a and list_b:\n",
    "\n",
    "```\n",
    "list_a = [[1, 2, 3], [5, 6, 7, 8], [10, 11, 12], [20, 21]]\n",
    "list_b = [[2, 3, 4, 5], [6, 9, 10], [11, 12, 13, 14], [21, 24, 25]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{2, 3}, {6}, {11, 12}, {21}]\n"
     ]
    }
   ],
   "source": [
    "list_a = [[1, 2, 3], [5, 6, 7, 8], [10, 11, 12], [20, 21]]\n",
    "list_b = [[2, 3, 4, 5], [6, 9, 10], [11, 12, 13, 14], [21, 24, 25]]\n",
    "\n",
    "def common_items(list1,list2):\n",
    "    list1_unique = set(list1)\n",
    "    inter = list1_unique.intersection(list2)\n",
    "    inter_list = list(inter)\n",
    "    return inter\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = [pool.apply(common_items,args=(la,lb)) for la,lb in zip(list_a,list_b)]\n",
    "pool.close()\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 \n",
    "\n",
    "Suppose you have three scripts named `script1.py`, `script2.py`, `script3.py`. Use `Pool.map()` to run them in parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "process = ('script1.py', 'script2.py', 'script3.py')\n",
    "           \n",
    "def run_python(process):\n",
    "    os.system('python {}'.format(process))\n",
    "\n",
    "pool = mp.Pool(process=3)\n",
    "pool.map(run_python,process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Normalize each row of 2d array (list) to vary between 0 and 1. Exceute in parallel.\n",
    "\n",
    "`list_a = [[2, 3, 4, 5], [6, 9, 10, 12], [11, 12, 13, 14], [21, 24, 25, 26]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.3333333333333333, 0.6666666666666666, 1.0], [0.0, 0.5, 0.6666666666666666, 1.0], [0.0, 0.3333333333333333, 0.6666666666666666, 1.0], [0.0, 0.6, 0.8, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "list_a = [[2, 3, 4, 5], [6, 9, 10, 12], [11, 12, 13, 14], [21, 24, 25, 26]]\n",
    "\n",
    "def normalize(list_1):\n",
    "    min1 = min(list_1)\n",
    "    max1 = max(list_1)\n",
    "    return [(i - min1)/(max1-min1) for i in list_1]\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = [pool.apply(normalize,args=(l1,)) for l1 in list_a]\n",
    "pool.close()\n",
    "print(results[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
